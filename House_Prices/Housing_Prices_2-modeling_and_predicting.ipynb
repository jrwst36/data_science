{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Prices: Modeling and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv('data/train.csv', index_col='Id')\n",
    "test = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Separate out the target values\n",
    "target = train.SalePrice\n",
    "train  = train.drop('SalePrice', axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data preprocessing\n",
    "### Convert 'MSSubClass' from int to str so that the column is treated categorically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MSSubClass'] = train.MSSubClass.astype('str')\n",
    "test['MSSubClass'] = test.MSSubClass.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert ordinal objects to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified mapping function\n",
    "def mapper(column, map_dictionary, df):\n",
    "    \"\"\"Short version to map and replace column\"\"\" \n",
    "    df[column] = df[column].map(map_dictionary)\n",
    "    \n",
    "# Function to map each column\n",
    "def column_mapper(df):\n",
    "    map_dict = {'Grvl':0, \"Pave\":1}\n",
    "    mapper('Street',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'Grvl':1, \"Pave\":2}\n",
    "    mapper('Alley', map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'IR3':0, 'IR2':1, \"IR1\":2, \"Reg\":3}\n",
    "    mapper('LotShape', map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'ELO':0, 'NoSeWa':1, \"NoSewr\":2, \"AllPub\":3}\n",
    "    mapper('Utilities', map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'Gtl':0, 'Mod':1, \"Sev\":2}\n",
    "    mapper('LandSlope',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'Po':0, 'Fa':1, \"TA\":2, \"Gd\":3, \"Ex\":4}\n",
    "    mapper('ExterQual',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'Po':0, 'Fa':1, \"TA\":2, \"Gd\":3, \"Ex\":4}\n",
    "    mapper('ExterCond',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan: 0, 'Po':1, 'Fa':2, \"TA\":3, \"Gd\":4, \"Ex\":5}\n",
    "    mapper('BsmtQual',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan: 0, 'Po':1, 'Fa':2, \"TA\":3, \"Gd\":4, \"Ex\":5}\n",
    "    mapper('BsmtCond',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan: 0, 'No':1, 'Mn':2, \"Av\":3, \"Gd\":4}\n",
    "    mapper('BsmtExposure',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan: 0, 'Unf':1, 'LwQ':2, \"Rec\":3, \"BLQ\":4, 'ALQ':5, 'GLQ': 6}\n",
    "    mapper('BsmtFinType1',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan: 0, 'Unf':1, 'LwQ':2, \"Rec\":3, \"BLQ\":4, 'ALQ':5, 'GLQ': 6}\n",
    "    mapper('BsmtFinType2',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'Po': 0, 'Fa':1, 'TA':2, \"Gd\":3, \"Ex\":4}\n",
    "    mapper('HeatingQC',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'N': 0, 'Y':1}\n",
    "    mapper('CentralAir',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'FuseP': 0, 'FuseF':1, 'Mix':2, np.nan:2, 'FuseA':3, 'SBrkr':4}\n",
    "    mapper('Electrical',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'Po': 0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}\n",
    "    mapper('KitchenQual',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'Sal': 0, 'Sev':1, 'Maj2':2, 'Maj1':3, 'Mod':4, 'Min2':5, 'Min1':6, 'Typ':7}\n",
    "    mapper('Functional',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'Po': 1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\n",
    "    mapper('FireplaceQu',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'Unf': 1, 'RFn':2, 'Fin':3}\n",
    "    mapper('GarageFinish',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'Po': 1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\n",
    "    mapper('GarageQual',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'Po': 1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\n",
    "    mapper('GarageCond',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {'N':0, 'P': 1, 'Y':2}\n",
    "    mapper('PavedDrive',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'Fa': 1, 'TA':2, 'Gd':3, 'Ex':4}\n",
    "    mapper('PoolQC',map_dictionary = map_dict, df=df)\n",
    "\n",
    "    map_dict = {np.nan:0, 'MnWw': 1, 'GdWo':2, 'MnPrv':3, 'GdPrv':4}\n",
    "    mapper('Fence',map_dictionary = map_dict, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns in the train and test set\n",
    "column_mapper(train)\n",
    "column_mapper(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list all columns with null values\n",
    "def null_columns_df(df):\n",
    "    null_count_df = pd.DataFrame(df.isnull().sum(), columns=['null_count'])\n",
    "    \n",
    "    # Redefine the dataframe to contain only null counts > 0\n",
    "    null_count_df = null_count_df[null_count_df.null_count > 0]\n",
    "    \n",
    "    dtype_list = []\n",
    "    for column in null_count_df.index:\n",
    "        dtype = df[column].dtype\n",
    "        dtype_list.append(dtype)\n",
    "     \n",
    "    # Create column to list the dtypes of each column\n",
    "    null_count_df['type'] = dtype_list\n",
    "    \n",
    "    return null_count_df[null_count_df.null_count > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found in the exploratory data analysis that the test data set has more columns with null values, and the train data set completely overlaps with the test data set. Therefore, we will us the test data set as a guide to deal with the null values.\n",
    "\n",
    "#### Object nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>16</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>76</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1408</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleType</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             null_count    type\n",
       "MSZoning              4  object\n",
       "Exterior1st           1  object\n",
       "Exterior2nd           1  object\n",
       "MasVnrType           16  object\n",
       "GarageType           76  object\n",
       "MiscFeature        1408  object\n",
       "SaleType              1  object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = null_columns_df(test)\n",
    "df.loc[ df.type == 'object',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_object(df):\n",
    "    # Columns to be filled with the mode.\n",
    "    fill = df.MSZoning.value_counts().idxmax()\n",
    "    df.MSZoning.fillna(fill, inplace=True)\n",
    "    \n",
    "    fill = df.Exterior1st.value_counts().idxmax()\n",
    "    df.Exterior1st.fillna(fill, inplace=True)\n",
    "    \n",
    "    fill = df.Exterior2nd.value_counts().idxmax()\n",
    "    df.Exterior2nd.fillna(fill, inplace=True)\n",
    "        \n",
    "    fill = df.MasVnrType.value_counts().idxmax()\n",
    "    df.MasVnrType.fillna(fill, inplace=True)\n",
    "    \n",
    "    fill = df.SaleType.value_counts().idxmax()\n",
    "    df.SaleType.fillna(fill, inplace=True)\n",
    "    \n",
    "    # Columns were null values are assumed to be no feature present\n",
    "    df.GarageType.fillna('no_garage', inplace=True)\n",
    "    \n",
    "    df.MiscFeature.fillna('no_feature', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_object(train)\n",
    "fillna_object(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>227</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>2</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>15</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>2</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>2</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenQual</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <td>2</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>78</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              null_count     type\n",
       "LotFrontage          227  float64\n",
       "Utilities              2  float64\n",
       "MasVnrArea            15  float64\n",
       "BsmtFinSF1             1  float64\n",
       "BsmtFinSF2             1  float64\n",
       "BsmtUnfSF              1  float64\n",
       "TotalBsmtSF            1  float64\n",
       "BsmtFullBath           2  float64\n",
       "BsmtHalfBath           2  float64\n",
       "KitchenQual            1  float64\n",
       "Functional             2  float64\n",
       "GarageYrBlt           78  float64\n",
       "GarageCars             1  float64\n",
       "GarageArea             1  float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = null_columns_df(test)\n",
    "df.loc[df.type != 'object',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_num(df):\n",
    "    # Columns to be filled with the median.\n",
    "    df.Utilities.fillna(df.Utilities.median(), inplace=True)\n",
    "    df.KitchenQual.fillna(df.KitchenQual.median(), inplace=True)\n",
    "    df.Functional.fillna(df.Functional.median(), inplace=True)\n",
    "    \n",
    "    # Columns were null values are assumed to be no feature present (value=0)\n",
    "    df.LotFrontage.fillna(0, inplace=True)    \n",
    "    df.MasVnrArea.fillna(0, inplace=True)\n",
    "    df.BsmtFinSF1.fillna(0, inplace=True)\n",
    "    df.BsmtFinSF2.fillna(0, inplace=True)\n",
    "    df.BsmtUnfSF.fillna(0, inplace=True)\n",
    "    df.BsmtHalfBath.fillna(0, inplace=True)\n",
    "    df.TotalBsmtSF.fillna(0, inplace=True)\n",
    "    df.BsmtFullBath.fillna(0, inplace=True)\n",
    "    df.BsmtFinSF2.fillna(0, inplace=True)\n",
    "    df.GarageCars.fillna(0, inplace=True)\n",
    "    df.GarageArea.fillna(0, inplace=True)\n",
    "    \n",
    "    # The GarageYrBlt is a problem as the null value likely means no garage.\n",
    "    # Using 0 would distort the data when scaled. I will set it to the median\n",
    "    df.GarageYrBlt.fillna(df.GarageYrBlt.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_num(train)\n",
    "fillna_num(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "2593    2207.0\n",
       "Name: GarageYrBlt, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.GarageYrBlt[test.GarageYrBlt > 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The house was built in 2006, so the garage is likely to be built in 2007\n",
    "test.loc[2593, 'GarageYrBlt'] = 2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Get dummy variables and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# Address the fact that not all categrical features are present, thus columns must be added\n",
    "train_columns = set(train.columns)\n",
    "test_columns = set(test.columns)\n",
    "\n",
    "# These columns must be added as 0's\n",
    "test_columns_zero = list(train_columns.difference(test_columns))\n",
    "train_columns_zero = list(test_columns.difference(train_columns))\n",
    "\n",
    "# Create these columns and set their values to 0\n",
    "def create_0_columns(df, column_list):\n",
    "    for column in column_list:\n",
    "        df[column] = 0\n",
    "\n",
    "create_0_columns(test, test_columns_zero)\n",
    "create_0_columns(train, train_columns_zero)\n",
    "\n",
    "# Keep the columns in the same order\n",
    "train_columns = train.columns\n",
    "test = test[train_columns]\n",
    "\n",
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sclr = StandardScaler()\n",
    "train = sclr.fit_transform(train)\n",
    "test = sclr.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to model the data\n",
    "***\n",
    "## Data fitting\n",
    "To fit the data we will use a linear support vector regressor. The LinearSVR fits very quickly with this data set size, so it is easy to use a grid search cross validation on a wide range of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.086663</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5700</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.732364</td>\n",
       "      <td>0.086919</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5600</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.732358</td>\n",
       "      <td>0.086514</td>\n",
       "      <td>3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6300</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.732358</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5600</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.732353</td>\n",
       "      <td>0.086859</td>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6200</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.732310</td>\n",
       "      <td>0.086586</td>\n",
       "      <td>6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6300</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.732307</td>\n",
       "      <td>0.086928</td>\n",
       "      <td>7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6200</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.732303</td>\n",
       "      <td>0.087295</td>\n",
       "      <td>8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5600</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.086669</td>\n",
       "      <td>9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6800</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.732271</td>\n",
       "      <td>0.086496</td>\n",
       "      <td>10</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6300</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score  std_test_score  rank_test_score param_epsilon param_C  \\\n",
       "144         0.732399        0.086663                1           5.4    5700   \n",
       "130         0.732364        0.086919                2             6    5600   \n",
       "272         0.732358        0.086514                3           6.2    6300   \n",
       "122         0.732358        0.087100                4           5.2    5600   \n",
       "252         0.732353        0.086859                5           6.2    6200   \n",
       "276         0.732310        0.086586                6           6.6    6300   \n",
       "248         0.732307        0.086928                7           5.8    6200   \n",
       "132         0.732303        0.087295                8           6.2    5600   \n",
       "376         0.732278        0.086669                9           6.6    6800   \n",
       "274         0.732271        0.086496               10           6.4    6300   \n",
       "\n",
       "              param_loss  \n",
       "144  epsilon_insensitive  \n",
       "130  epsilon_insensitive  \n",
       "272  epsilon_insensitive  \n",
       "122  epsilon_insensitive  \n",
       "252  epsilon_insensitive  \n",
       "276  epsilon_insensitive  \n",
       "248  epsilon_insensitive  \n",
       "132  epsilon_insensitive  \n",
       "376  epsilon_insensitive  \n",
       "274  epsilon_insensitive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param={'C': list(range(5000,7010,100)), \n",
    "       'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "       'epsilon': np.array(range(50,70,2))/10}\n",
    "\n",
    "svr = LinearSVR(random_state=2049)\n",
    "gridCV = GridSearchCV(svr, param, \n",
    "                      cv=3, verbose=0,\n",
    "                      return_train_score=True, n_jobs=-1)\n",
    "gridCV.fit(train, target)\n",
    "\n",
    "# Make and print results dataframe\n",
    "cv_result = pd.DataFrame(gridCV.cv_results_)\n",
    "param_columns = ['param_'+key for key in list(param.keys())]\n",
    "cv_columns = ['mean_test_score', 'std_test_score', 'rank_test_score'] + param_columns\n",
    "cv_result[cv_columns].sort_values('rank_test_score').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the estimated Kaggle score.\n",
    "The scoring system as listed on the competition site\n",
    "> Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated score: 0.12961080050401005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state = 2049, test_size=.1)\n",
    "\n",
    "svr = LinearSVR(random_state=2049, C=5700, loss='epsilon_insensitive', epsilon=5.4)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "prediction = svr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "score = mean_squared_error(np.log(y_test.values), np.nan_to_num(np.log(prediction)))\n",
    "print('Estimated score:',np.sqrt(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Prepare final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>124604.101042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>152308.866356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>185831.996820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>192284.529473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>220566.600546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SalePrice\n",
       "Id                 \n",
       "1461  124604.101042\n",
       "1462  152308.866356\n",
       "1463  185831.996820\n",
       "1464  192284.529473\n",
       "1465  220566.600546"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = LinearSVR(random_state=2049, C=5700, loss='epsilon_insensitive', epsilon=5.4)\n",
    "svr.fit(train, target)\n",
    "\n",
    "prediction = svr.predict(test)\n",
    "\n",
    "test_df = pd.read_csv('data/test.csv',index_col='Id')\n",
    "submission_df = pd.DataFrame(data=prediction, \n",
    "                             columns=['SalePrice'], \n",
    "                             index=test_df.index)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
